import asyncio
import aiohttp
import async_timeout
import logging  # for logging rate limit warnings and other messages
import os  # for reading API key
import re  # for matching endpoint from request URL
import time
import math
import pandas as pd
import numpy as np
import multiprocessing as mp

logging.basicConfig(filename="logfilename.log", level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# Define your API URL and any required headers
API_URL = 'https://sccr8pgns0.execute-api.us-east-1.amazonaws.com/dev/locations'  # Replace with your actual API URL


# callculate the distance between two points based on haversine formula
# the code was generated by the help of Vscode extension GitHub Copilot
# input: lat1, lon1, lat2, lon2
# output: distance in km
def haversine(lat1, lon1, lat2, lon2):
    R = 6371 # Radius of the earth in km
    
    # distance between latitudes and logituds
    # convert degree to radian
    dlat = np.radians(lat2-lat1) 
    dlon = np.radians(lon2-lon1) 
    
    # haversine formula
    a = np.sin(dlat/2) * np.sin(dlat/2) + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon/2) * np.sin(dlon/2)
    c = 2 * np.atan2(np.sqrt(a), np.sqrt(1-a))
    return R * c
    
# Load the data with a wikipedia link
airports = pd.read_csv('airports_w_wiki.csv') 
# Function to find the nearest airport to a given user location
def find_nearest_airport(data):
    try: 
            user_lat = float(data["data"]['latitude']['N'])
            user_lon = float(data["data"]['longitude']['N'])
            
            distances = haversine(user_lat, user_lon, airports['latitude_deg'].values, airports['longitude_deg'].values)
            min_index = np.argmin(distances)
            nearest_airport_id = airports.iloc[min_index]['id']
            
            return {'user_id': int(data["data"]['user_id']['N']), 'airport_id': int(nearest_airport_id)}
    except Exception as e:
        logging.error(f"Error processing user {data}: {e}")
        return None

# Function to fetch data from the API
async def fetch(session, url):
    async with session.get(url) as response:
        if response.status == 200:
            data = await response.json()
            return data
        else:
            logging.error(f"Error processing user {url}: {response.status}")
            return None

async def fetch_all(urls, loop):
    conn = aiohttp.TCPConnector(limit=60)
    async with aiohttp.ClientSession(connector=conn, loop=loop) as session:
        results = await asyncio.gather(*[fetch(session, url) for url in urls], return_exceptions=True)
        return [res for res in results if res is not None]


async def main():
    ids = np.arange(100000)
    urls = list(map(lambda id: f"{API_URL}/{id}", ids))
    start2_time = time.time()    
    loop = asyncio.get_event_loop()
    responses = await fetch_all(urls, loop)
    
    end2_time = time.time()
    print(f"Retrieve {len(responses)} data points in {end2_time - start2_time} seconds.")

    start3_time = time.time()
    
    # Number of workers
    num_workers = mp.cpu_count()
    
    # Create a pool of workers
    pool = mp.Pool(num_workers)
    # Use pool.map to parallelize the process of finding the nearest airport
    data_list = pool.map(find_nearest_airport, responses)
    # Close the pool and wait for the work to finish
    pool.close()
    pool.join()
                 
    end3_time = time.time()
    print(f"Calculate nearest airport {len(data_list)} data points in {end3_time - start3_time} seconds.")

    return data_list

if __name__ == "__main__":
    # Measure the time taken
    start_time = time.time()
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # If the loop is already running, use it to run the main coroutine
            task = loop.create_task(main())
            loop.run_until_complete(task)
        else:
            # If no loop is running, start a new event loop
            results = loop.run_until_complete(main())
    except RuntimeError as e:
        logging.error(f"RuntimeError: {e}")
    
    # Convert the data list to a DataFrame
    df = pd.DataFrame(results)

    # Save the DataFrame to a CSV file
    df.to_csv('user_closest_airport.csv', index=False)
    print("Saved results to user_closest_airport.csv")
    end_time = time.time()
    print(f"Retrieved and processed {len(results)} data points in {end_time - start_time} seconds.")
